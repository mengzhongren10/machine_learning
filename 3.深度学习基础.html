激活函数
    RELU  解决梯度消失问题
激活步长
    RMSProp
    Adadelta
    Adagrad
    Adam
    SGD

算法选择
    1.优先考虑SGD或Adam
    2.需要根据数据集来选择
    3.根据需求：快速验证效果，选Adam；模型优化，采用精调的SGD
    4.考虑不同算法的组合：先用adam快速下降，再用SGD充分调优
    5.数据集一定要充分的打散

CNN的基本组件
    1.卷积层
       激活函数
       主要作用：提取局部特征，需要设定卷积核
    2.池化层
       平均池化
       最大化池化
       作用：
           特征融合，降维
           无参数需要学习
       
    3.全连接层
    
    4.CNN-Softmax层
      指数归一化
      得出分类的概率值



    
